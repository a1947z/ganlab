<!DOCTYPE html>
<html>

<head>
  <meta charset="UTF-8">
  <script src="../node_modules/@bower_components/webcomponentsjs/webcomponents-lite.min.js"></script>
  <link rel="import" href="ganlab.html">

  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/dialog-polyfill/0.4.9/dialog-polyfill.min.css" />
  <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/dialog-polyfill/0.4.9/dialog-polyfill.min.js"></script>
  <script src="../lib/support.js"></script>
  
    <!-- 分享卡片 -->
    <meta name="twitter:card" content="summary_large_image" />
    <meta name="twitter:site" content="@minsukkahng" />
    <meta name="twitter:creator" content="@minsukkahng" />
    <meta property="og:url" content="https://poloclub.github.io/ganlab/" />
    <meta property="og:title" content="GAN 实验室" />
    <meta property="og:description"
      content="GAN 实验室：在浏览器中体验生成对抗网络" />
    <meta property="og:image" content="https://poloclub.github.io/ganlab/images/share.png" />

  <title>GAN 实验室：在浏览器中体验生成对抗网络</title>
  <style>
    html {
      width: 100%;
      height: 100%;
    }

    body {
      font-family: "Roboto", "Helvetica", "Arial", sans-serif;
      margin: 0;
      min-width: 1442px;
      width: 100%;
      height: 100%;
      --discriminator-color: rgb(68, 124, 228);
      --generator-color: rgb(163, 62, 189);
      --gradient-color: rgb(196, 20, 219);
      --real-data-color: rgb(0, 136, 55);
    }
  
    #top-bar {
      background-color: #183D4E;
      color: #f5f5f5;
      font-size: 16px;
      padding: 7px 0 6px;
    }

    #top-bar-panel-container {
      align-items: center;
      display: flex;
      margin-left: auto;
      margin-right: auto;
      justify-content: space-between;
      width: 1442px;
    }

    @media screen and (min-device-width: 1024px) and (max-width: 1442px) {
      #top-bar-panel-container {
        margin-left: 0;
        width: 98.5vw;
      }
    }

    #tool-description {
      padding-left: 20px;
    }

    #source-link {
      padding-right: 20px;
    }

    #source-link a {
      color: #f0f0f0;
      font-size: 14px;
      text-decoration: none;
    }

    #loading {
      background-color: #f7f7f7;
      font-size: 40px;
      height: 140px;
      line-height: 40px;
      padding-top: 60px;
      position: absolute;
      text-align: center;
      width: 100%;
      z-index: -1;
    }

    #loading small {
      font-size: 20px;
    }

    #demo {      
      min-height: 200px;
      width: 100%;
    }

    #description {
      margin-bottom: 60px;
      margin-left: auto;
      margin-right: auto;
      max-width: 660px;
    }

    #description h2 {
      color: #444;
      font-size: 32px;
      font-weight: 450;
      margin-bottom: 12px;
      margin-top: 60px;
    }

    #description h4 {
      color: #444;
      font-size: 24px;
      font-weight: 450;
      margin-bottom: 8px;
      margin-top: 44px;
    }

    #description p {
      margin: 16px 0;
    }

    #description p, 
    #description div,
    #description li,
    #description dt,
    #description dd {
      color: #555;
      font-size: 17px;
      line-height: 1.6;
    }
      
    #description .supporting-figure {
      margin-bottom: 35px;
      margin-top: 30px;
    }
    
    #description .figure-caption {
      font-size: 14px;
      margin-top: 5px;
    }
      
    #description dt {
      display: list-item;
      list-style-type: disc;
      margin-left: 30px;
    }

    #description ul {
      margin-top: -10px;
    }

    #description a, 
    #description .video-part-link {
      color: #0D658C;
      cursor: pointer;
      font-weight: normal;
      text-decoration: none;
    }
      
    #description a:hover, 
    #description .video-part-link:hover {
      text-decoration: underline;
    }

    #description div.citation {
      font-size: 14px;
      line-height: 20px;
      margin-top: 0px;
      padding: 20px 10px 0 110px;
    }
  </style>
</head>

<body>
  <div id="top-bar">
    <div id="top-bar-panel-container" class="panel-container">
      <div id="tool-description">
        在浏览器中体验生成对抗网络（GANs）          
      </div>
      <div id="source-link">
        <a href="https://github.com/poloclub/ganlab" title="GitHub 上的源代码">
          本项目代码来自Github项目Ganlab&nbsp;
          <img src="images/github-mark.png" />
        </a>
      </div>
    </div>
  </div>      
      
  <div id="demo">
    <div id="loading">
      正在加载...
      <br />
      <small>可能需要几十秒的时间。</small>
    </div>
    <gan-lab></gan-lab>
  </div>

  <div id="description">
    <h2>什么是 GAN？</h2>
    <p>
      许多机器学习系统会处理复杂的输入（例如图像），并输出简单的结果（例如“猫”这样的标签）。相比之下，生成模型的目标则恰恰相反：它接受少量输入（可能是几个随机数），并生成复杂的输出，例如逼真的人脸图像。<strong>生成对抗网络（GAN）</strong>是一种特别有效的生成模型，<a href="https://arxiv.org/pdf/1406.2661.pdf" title="Goodfellow 等人于 2014 年发表的原始论文">它是在几年前被提出的</a>，在机器学习领域引起了广泛关注。 
    </p>
    
    <p>
      你可能会好奇，为什么我们需要一个能够生成逼真图像或其他数据模拟的系统。除了内在的智力挑战外，事实证明，这是一个非常实用的工具，<a href="https://arxiv.org/pdf/1701.00160.pdf" title="请参阅本教程论文的第 4 页">其应用范围从艺术创作到模糊图像增强等</a>。
    </p>      

    <h2>GAN 是如何工作的？</h2>
    <p>
      机器“从零开始”创建逼真图像的想法似乎很神奇，但 GAN 使用了<em>两个关键技巧</em>，将一个看似不可能的模糊目标变为现实。
    </p>
    
    <p>
      第一个想法并非 GAN 所独有，即使用<em>随机性</em>作为输入。从基本层面来看，这是有道理的：如果每次运行系统都生成相同的人脸，那就没什么意思了。同样重要的是，从概率的角度思考也有助于我们将图像生成问题转化为一个自然的数学框架。显然，我们不希望随机选择图像，因为这样只会产生噪声。相反，我们希望系统学习哪些图像可能是人脸，哪些不是。从数学上讲，这涉及对图像的概率分布进行建模，即一个函数，它告诉我们哪些图像可能是人脸，哪些不是。这类问题——在高维空间上对函数进行建模——正是神经网络擅长的。
    </p>
    
    <p>      
      定义 GAN 的重大见解是将这个建模问题设置为一种竞赛。这就是“对抗”这个词的由来。关键思想是构建两个相互竞争的网络：一个<span style="color: var(--generator-color);"><strong>生成器</strong></span>和一个<span style="color: var(--discriminator-color);"><strong>判别器</strong></span>。生成器尝试创建随机的<span style="color: var(--generator-color);">合成输出</span>（例如人脸图像），而判别器则尝试将这些合成输出与<span style="color: var(--real-data-color);">真实输出</span>（例如名人数据库）区分开来。我们希望，随着这两个网络的对抗，它们都会变得越来越好——最终结果是一个能够生成逼真输出的生成器网络。
    </p>
    
    <p>      
      总结一下：<strong><em>生成对抗网络</em></strong>是一种神经网络，它学习从特定分布中选择样本（这就是“生成”这个词的由来），并且通过设置竞争来实现这一点（因此称为“对抗”）。
    </p>

    <h2>可视化中展示了什么？</h2>
    <p>
      GAN 是复杂的模型，可视化中包含了很多信息。以下是基本概念。
    </p>
    
    <p>
      首先，我们并没有可视化像生成逼真图像这样复杂的内容。相反，我们展示的是一个学习二维空间中数据点分布的 GAN。虽然这种简单的模型没有实际应用，但它更容易展示系统的工作原理。一方面，二维（x, y）空间中的概率分布比高分辨率图像空间中的分布更容易可视化。  
    </p>

    <h4>
      选择数据分布。
    </h4>
    
    <p>
      在顶部，你可以选择一个 GAN 要学习的概率分布，我们将其可视化为<span style="color: var(--real-data-color);">一组数据样本</span>。选择后，我们会在两个地方显示它们：左边的<em>模型概览图</em>中显示较小的版本；右边的<em>分层分布</em>视图中显示较大的版本。
    </p>
    
    <div class="supporting-figure">
      <img src="figures/figure-data-selected.png" />
      <div class="figure-caption">
        图 1. 所选数据分布在两个地方显示。
      </div>
    </div>
    
    <p>
      我们设计这两个视图是为了帮助你更好地理解 GAN 如何生成逼真的样本：
      <br />
      (1) <strong>模型概览图</strong>展示了 GAN 的架构、主要组件及其连接方式，还可视化了组件产生的结果；
      <br />
      (2) <strong>分层分布</strong>视图叠加了模型概览图中组件的可视化效果，这样在分析模型时，你可以更轻松地比较组件的输出。
    </p>
    
    <h4>
      开始训练。
    </h4>
    
    <p>
      要开始训练 GAN 模型，请点击工具栏上的播放按钮 (<img class="icon" src="figures/figure-icon-play.png" />)。除了从你选择的分布中获取的<span style="color: var(--real-data-color);">真实样本</span>，你还会看到模型生成的<span style="color: var(--generator-color);">假样本</span>。随着训练的进行，假样本的位置会不断更新。一个完美的 GAN 会生成与真实样本分布无法区分的假样本。当这种情况发生时，在分层分布视图中，你会看到两个分布完美重叠。
    </p>
    
    <div class="supporting-figure">
      <img src="figures/figure-animated-ring.gif" />
      <div class="figure-caption">
        图 2. 随着训练的进行，假样本的位置不断更新。然后，真实样本和假样本的分布完美重叠。
      </div>
    </div>
    
    <h4>
      可视化生成器和判别器。
    </h4>
    
    <p>
      请记住，GAN 中的<span style="color: var(--generator-color);">生成器</span>和<span style="color: var(--discriminator-color);">判别器</span>正在进行一场小竞赛，它们相互对抗，迭代更新<span style="color: var(--generator-color);">假样本</span>，使其更接近<span style="color: var(--real-data-color);">真实样本</span>。GAN 实验室可视化了它们之间的交互。 
    </p>
    
    <p>
      <strong>生成器。</strong>
      如前所述，<span style="color: var(--generator-color);">生成器</span>是一个将随机输入转换为合成输出的函数。在 GAN 实验室中，随机输入是一个具有 (x, y) 值的二维样本（从均匀分布或高斯分布中抽取），输出也是一个二维样本，但映射到了不同的位置，即<span style="color: var(--generator-color);">假样本</span>。一种可视化这种映射的方法是使用<em>流形</em> <small><a href="http://colah.github.io/posts/2014-03-NN-Manifolds-Topology/">[Olah, 2014]</a></small>。输入空间表示为一个均匀的正方形网格。当函数将输入空间中的位置映射到新位置时，如果我们可视化输出，整个网格（现在由不规则四边形组成）看起来就像原始规则网格的变形版本。每个（变形后的）单元格的面积（或密度）现在发生了变化，我们将密度编码为不透明度，因此不透明度越高意味着在更小的空间中有更多的样本。一个非常精细的流形看起来几乎与假样本的可视化相同。这种可视化展示了生成器如何学习一个映射函数，使其输出看起来与<span style="color: var(--real-data-color);">真实样本</span>的分布相似。
    </p>
    
    <div class="supporting-figure">
      <img src="figures/figure-generator-transformation.png" />
      <div class="figure-caption">
        图 3. 生成器的数据转换被可视化为一个流形，它将输入噪声（最左边）转换为假样本（最右边）。
      </div>
    </div>
    
    <p>
      <strong>判别器。</strong>
      当生成器创建<span style="color: var(--generator-color);">假样本</span>时，<span style="color: var(--discriminator-color);">判别器</span>（一个二元分类器）尝试将它们与<span style="color: var(--real-data-color);">真实样本</span>区分开来。GAN 实验室将其决策边界可视化为一个二维热力图（类似于<a href="http://playground.tensorflow.org"><em>TensorFlow 游乐场</em></a>）。网格单元格的背景颜色编码了分类器结果的置信度值。<span style="background-color: var(--real-data-color); color: white;">深绿色</span>表示该区域的样本更有可能是真实的；<span style="background-color: var(--generator-color); color: white;">深紫色</span>表示更有可能是假的。当 GAN 接近最优状态时，整个热力图将整体变为<span style="background-color: rgb(117, 117, 117); color: white;">灰色</span>，这表明判别器无法再轻易区分假样本和真实样本。
    </p>
    
    <div class="supporting-figure">
      <img src="figures/figure-discriminator-heatmap.png" />
      <div class="figure-caption">
        图 4. 判别器的性能可以通过二维热力图来解释。在这里，判别器表现良好，因为大多数真实样本位于其分类表面的绿色区域（假样本位于紫色区域）。
      </div>
    </div>
    
    <h4>
      理解生成器和判别器之间的相互作用。
    </h4>
    
    <p>
      在 GAN 中，两个网络在迭代更新过程中相互影响。GAN 实验室的一个重要用途是通过其可视化来学习<span style="color: var(--generator-color);">生成器</span>如何逐步更新自己，以生成越来越逼真的假样本。生成器通过试图欺骗<span style="color: var(--discriminator-color);">判别器</span>来实现这一点。当判别器将<span style="color: var(--generator-color);">假样本</span>分类为<span style="color: var(--real-data-color);">真实样本</span>时，生成器的损失值会降低（这对判别器不利，但对生成器有利）。GAN 实验室将假样本的梯度可视化为<span style="color: var(--gradient-color);">粉色线条</span>，这样生成器就可以实现其目标。
    </p>

    <div class="supporting-figure">
      <img src="figures/figure-gradients-interplay.png" />
      <div class="figure-caption">
        图 5. 假样本的移动方向由生成器的梯度（粉色线条）指示，这些梯度基于样本的当前位置和判别器的当前分类表面（通过背景颜色可视化）。
      </div>
    </div>
    
    <p>
      通过这种方式，<span style="color: var(--generator-color);">生成器</span>逐渐改进，以生成更逼真的样本。一旦假样本更新，<span style="color: var(--discriminator-color);">判别器</span>将相应地更新其决策边界，等待下一批试图欺骗它的假样本。这个迭代更新过程会一直持续，直到判别器无法区分<span style="color: var(--real-data-color);">真实</span>和<span style="color: var(--generator-color);">假</span>样本。
    </p>
    
    <h4>
      体验交互式功能。
    </h4>
    
    <p>
      GAN 实验室有许多很酷的功能，支持交互式实验。
      <dl>
        <dt>
          交互式超参数调整
        </dt>
        <dd>
          点击编辑图标 (<img class="icon" src="figures/figure-icon-edit.png" />) 以显示各个超参数，并在训练过程中实时编辑它们。
        </dd>
        <dt>
          用户自定义数据分布
        </dt>
        <dd>
          如果你不喜欢我们提供的分布选择，可以点击数据分布列表末尾的图标 (<img class="icon" src="figures/figure-icon-draw.png" />) 绘制自己的分布。
        </dd>
        <dt>
          慢动作模式
        </dt>
        <dd>
          跟不上动画的节奏？你可以点击慢动作图标 (<img class="icon" src="figures/figure-icon-slow.png" />) 进入慢动作模式。 
          <a class="video-part-link" data-start="111" data-end="138">查看此视频</a>
        </dd>
        <dt>
          手动逐步执行
        </dt>
        <dd>
          如果你想要更多控制，可以点击图标 (<img class="icon" src="figures/figure-icon-step.png" />) 手动逐步训练单个迭代步骤。
          <a class="video-part-link" data-start="139" data-end="190">查看此视频</a>
        </dd>
      </dl>
    </p>
    
    <h2>它是如何实现的？</h2>
    <p>
      GAN 实验室使用了 <a href="https://js.tensorflow.org/"><em>TensorFlow.js</em></a>，这是一个在浏览器中运行的 GPU 加速深度学习库。从模型训练到可视化，一切都用 JavaScript 实现。你只需要像 Chrome 这样的浏览器就可以运行 GAN 实验室。我们的实现方法大大拓宽了人们使用深度学习交互式工具的途径。源代码可以在 <a href="https://github.com/poloclub/ganlab">GitHub</a> 上找到。
    </p>

    <h2>谁开发了 GAN 实验室？</h2>
    <p>
      GAN 实验室由 <a href="http://minsuk.com">Minsuk Kahng</a>、<a href="https://twitter.com/nsthorat">Nikhil Thorat</a>、<a href="https://www.cc.gatech.edu/~dchau/">Polo Chau</a>、<a href="http://www.fernandaviegas.com/">Fernanda Viégas</a> 和 <a href="http://www.bewitched.com/">Martin Wattenberg</a> 创建，这是佐治亚理工学院和谷歌 Brain/<a href="https://ai.google/research/teams/brain/pair">PAIR</a> 之间研究合作的成果。我们还感谢 Shan Carter 和 Daniel Smilkov、<a href="https://research.google.com/bigpicture/">谷歌大图景团队</a>、<a href="https://ai.google/research/teams/brain/pair">谷歌人机交互研究团队（PAIR）</a> 以及 <a href="http://vis.gatech.edu/">佐治亚理工学院可视化实验室</a> 提供的反馈。
    </p>
    
    <p style="margin-bottom: 0;">
      如需更多信息，请查看 <a href="http://minsuk.com/research/papers/kahng-ganlab-vast2018.pdf">我们的研究论文</a>：     
    </p>

    <a href="http://minsuk.com/research/papers/kahng-ganlab-vast2018.pdf">
      <img src="figures/figure-paper-screenshot.png" style="float: left;" />
    </a>

    <div class="citation">      
      <a href="http://minsuk.com">Minsuk Kahng</a>、<a href="https://twitter.com/nsthorat">Nikhil Thorat</a>、<a href="https://www.cc.gatech.edu/~dchau/">Polo Chau</a>、<a href="http://www.fernandaviegas.com/">Fernanda Viégas</a> 和 <a href="http://www.bewitched.com/">Martin Wattenberg</a>。“GAN 实验室：通过交互式可视化实验理解复杂的深度生成模型。”<i>IEEE 可视化与计算机图形学汇刊，25(1) (<a href="http://ieeevis.org/year/2018/welcome">VAST 2018</a>)</i>，2019 年 1 月。
    </div>
  </div>

  <script type="text/javascript">
    const tag = document.createElement('script');
    tag.id = 'iframe-demo';
    tag.src = 'https://www.youtube.com/iframe_api';
    const firstScriptTag = document.getElementsByTagName('script')[0];
    firstScriptTag.parentNode.insertBefore(tag, firstScriptTag);
  
    let player;
    function onYouTubeIframeAPIReady() {
      player = new YT.Player('video-demo-iframe', {
        events: {
          'onReady': onPlayerReady
        }
      });
    }
    function onPlayerReady(event) {
      player.mute()
    }
    
    const videoLinks = document.querySelectorAll('.video-part-link');
    Array.from(videoLinks).forEach((linkElement) => {
      linkElement.addEventListener('click', () => {
        const startSecond = linkElement.getAttribute('data-start');
        player.seekTo(startSecond);
        player.playVideo();
      });
    });
  </script>
</body>

</html>
    